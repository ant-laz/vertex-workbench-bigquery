{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08133e5-25d7-45a4-9a3e-a52e39f3d5e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copyright 2025 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f36c9b9-43ff-4b26-96ae-b84798a480a3",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "\n",
    "This notebook offers demonstrations of different methods of querying data that is stored in BigQuery from within the JupyterLab interface of your Vertex AI Workbench instance.\n",
    "\n",
    "Confused ? Let's define each of these terms in case they're new to you\n",
    "\n",
    " * **BigQuery** BigQuery is a fully managed, AI-ready data platform that helps you manage and analyze your data with built-in features like machine learning, search, geospatial analysis, and business intelligence. BigQuery's serverless architecture lets you use languages like SQL and Python to answer your organization's biggest questions with zero infrastructure management.\n",
    " \n",
    " * **JupyterLab**  JupyterLab is a highly extensible, feature-rich notebook authoring application and editing environment, and is a part of Project Jupyter, a large umbrella project centered around the goal of providing tools (and standards) for interactive computing with computational notebooks.\n",
    " \n",
    " * **Vertex AI Workbench instance** Vertex AI Workbench instances are Jupyter notebook-based development environments on Google Cloud for the entire data science workflow. Vertex AI Workbench instances are prepackaged with JupyterLab. Vertex AI Workbench instances have integrations and features can make it easier to access your data, process data faster, schedule notebook runs, and more.\n",
    " \n",
    "For most of these methods, we will use a **Python JupyterLab Kernel**. In the Jupyter architecture, kernels are separate processes started by the server that run your code in different programming languages and environments.  We will use the IPython Jupyter Kernel that comes prepackaged with Vertex AI Workbench Instances. This will allow us to execute Python code in this notebook interactively.\n",
    "\n",
    "Reference: \n",
    "\n",
    "https://cloud.google.com/bigquery/docs/introduction\n",
    "\n",
    "https://jupyterlab.readthedocs.io/en/latest/user/interface.html\n",
    "\n",
    "https://cloud.google.com/vertex-ai/docs/workbench/instances/introduction\n",
    "\n",
    "https://jupyterlab.readthedocs.io/en/latest/user/documents_kernels.html#kernel-backed-documents\n",
    "\n",
    "https://ipython.readthedocs.io/en/stable/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab43f52-c2fb-461b-99a2-15f2b26b3b48",
   "metadata": {},
   "source": [
    "# Method 1 : Using the BigQuery Pane in Vertex AI workbnench\n",
    "\n",
    "This is Method 1 of querying data that is stored in BigQuery from within the JupyterLab interface of your Vertex AI Workbench instance.\n",
    "\n",
    "BigQuery is integrated into the the JupyterLab interface of your Vertex AI Workbench instance.\n",
    "\n",
    "Through this integration you can use a BigQuery pane that lists available projects and datasets. \n",
    "\n",
    "Let's use this BigQuery pane now to explore some BigQuery public datasets. \n",
    "\n",
    " * select project \"bigquery-public-data\"\n",
    "   * select datatset \"google_trends\"\n",
    "     * select table \"international_top_terms\"\n",
    "       * click \"preview\" to see a sample of rows from this table\n",
    "       * click \"query table\" to open the Stand-alone BigQuery query editor opens as a separate tab in JupyterLab.\n",
    "\n",
    "Reference : \n",
    "\n",
    "https://cloud.google.com/vertex-ai/docs/workbench/instances/bigquery#browse_resources\n",
    "\n",
    "https://cloud.google.com/vertex-ai/docs/workbench/instances/bigquery#stand-alone\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73469eb3-379b-40a0-8e48-fe135a074578",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Method 2 : Using the %%bigquery magic command\n",
    "\n",
    "This is Method 2 of querying data that is stored in BigQuery from within the JupyterLab interface of your Vertex AI Workbench instance.\n",
    "\n",
    "For this method, it is required to use the IPython Jupyter Kernel that comes prepackaged with Vertex AI Workbench Instances. Please select & connect to it now.\n",
    "\n",
    "The IPython Jupyter Kernel has a feature called \"cell magics\" which are handy commands built into the IPython kernel that make it easy to perform particular tasks.\n",
    "\n",
    "BigQuery has developed \"cell magics\" to make it easy to execute SQL queries. There are two BigQuery \"cell magics\" \n",
    "\n",
    "1. %%bigquery\n",
    "\n",
    "  *  Behind the scenes, the %%bigquery magic command uses the BigQuery client library for Python to run the given query\n",
    "  *  Then convert the results to a pandas DataFrame \n",
    "  *  Then display results.\n",
    "\n",
    "2. %%bigquery my_pandas_data_frame\n",
    "\n",
    "  *  Behind the scenes, the %%bigquery magic command uses the BigQuery client library for Python to run the given query\n",
    "  *  Then convert the results to a pandas DataFrame \n",
    "  *  Then save the pandas DataFrame to the variable my_pandas_data_frame\n",
    "  \n",
    "See exampe of these two \"cell magics\" below\n",
    "\n",
    "Reference:\n",
    "\n",
    "https://cloud.google.com/vertex-ai/docs/workbench/instances/bigquery#query_data_by_using_the_bigquery_magic_command\n",
    "\n",
    "https://ipython.readthedocs.io/en/stable/interactive/magics.html#cell-magics\n",
    "\n",
    "https://ipython.readthedocs.io/en/stable/interactive/magics.html#line-magics\n",
    "\n",
    "https://cloud.google.com/python/docs/reference/bigquery/latest/magics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40035527-b288-4384-a072-1fa7bb7d569c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "SELECT\n",
    "  country_code,\n",
    "  country_name,\n",
    "  COUNT(DISTINCT region_code) AS num_regions\n",
    "FROM\n",
    "  `bigquery-public-data.google_trends.international_top_terms`\n",
    "WHERE\n",
    "  refresh_date = DATE_SUB(CURRENT_DATE, INTERVAL 1 DAY)\n",
    "GROUP BY\n",
    "  country_code,\n",
    "  country_name\n",
    "ORDER BY\n",
    "  num_regions DESC;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623f0cd6-a05f-412f-bdc2-5f0afcee7b84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery regions_by_country\n",
    "SELECT\n",
    "  country_code,\n",
    "  country_name,\n",
    "  COUNT(DISTINCT region_code) AS num_regions\n",
    "FROM\n",
    "  `bigquery-public-data.google_trends.international_top_terms`\n",
    "WHERE\n",
    "  refresh_date = DATE_SUB(CURRENT_DATE, INTERVAL 1 DAY)\n",
    "GROUP BY\n",
    "  country_code, country_name\n",
    "ORDER BY\n",
    "  num_regions DESC;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c37135f-29e9-47a4-bb1b-a1d4eef75910",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "regions_by_country.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd7abff-6c1c-4a6b-987b-c0831798ec71",
   "metadata": {},
   "source": [
    "# Method 3 : Using the BigQuery python client library \n",
    "\n",
    "This is Method 3 of querying data that is stored in BigQuery from within the JupyterLab interface of your Vertex AI Workbench instance.\n",
    "\n",
    "For this method, it is required to use the IPython Jupyter Kernel that comes prepackaged with Vertex AI Workbench Instances. Please select & connect to it now.\n",
    "\n",
    "As per the example below, using the BigQuery client library involves: \n",
    "\n",
    "1. importing the library\n",
    "2. initialing a BigQuery client object\n",
    "3. defining your SQL query\n",
    "4. getting the BigQuery client object to execute SQL and return a pandas Dataframe\n",
    "5. with the returned pandas Dataframe you can use a number of Python data analysis, data wrangling, and visualization libraries\n",
    "\n",
    "\n",
    "\n",
    "Reference :\n",
    "\n",
    "https://cloud.google.com/vertex-ai/docs/workbench/instances/bigquery#query_data_by_using_the_client_library_directly\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a44edb7-75bd-4392-8191-aa3dda5f0b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e850be-7740-424e-be81-e5191f61ad7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "WITH\n",
    "  TopTermsByDate AS (\n",
    "    SELECT DISTINCT refresh_date AS date, term\n",
    "    FROM `bigquery-public-data.google_trends.top_terms`\n",
    "  ),\n",
    "  DistinctDates AS (\n",
    "    SELECT DISTINCT date\n",
    "    FROM TopTermsByDate\n",
    "  )\n",
    "SELECT\n",
    "  DATE_DIFF(Dates2.date, Date1Terms.date, DAY)\n",
    "    AS days_apart,\n",
    "  COUNT(DISTINCT (Dates2.date || Date1Terms.date))\n",
    "    AS num_date_pairs,\n",
    "  COUNT(Date1Terms.term) AS num_date1_terms,\n",
    "  SUM(IF(Date2Terms.term IS NOT NULL, 1, 0))\n",
    "    AS overlap_terms,\n",
    "  SAFE_DIVIDE(\n",
    "    SUM(IF(Date2Terms.term IS NOT NULL, 1, 0)),\n",
    "    COUNT(Date1Terms.term)\n",
    "    ) AS pct_overlap_terms\n",
    "FROM\n",
    "  TopTermsByDate AS Date1Terms\n",
    "CROSS JOIN\n",
    "  DistinctDates AS Dates2\n",
    "LEFT JOIN\n",
    "  TopTermsByDate AS Date2Terms\n",
    "  ON\n",
    "    Dates2.date = Date2Terms.date\n",
    "    AND Date1Terms.term = Date2Terms.term\n",
    "WHERE\n",
    "  Date1Terms.date <= Dates2.date\n",
    "GROUP BY\n",
    "  days_apart\n",
    "\n",
    "ORDER BY\n",
    "  days_apart;\n",
    "\"\"\"\n",
    "pct_overlap_terms_by_days_apart = client.query(sql).to_dataframe()\n",
    "\n",
    "pct_overlap_terms_by_days_apart.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c563e2b-ef6b-4882-bed8-feb9691ccdc5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Method 4 : Using the BigQuery integration into Vertex AI workbench\n",
    "\n",
    "This is Method 4 of querying data that is stored in BigQuery from within the JupyterLab interface of your Vertex AI Workbench instance.\n",
    "\n",
    "The In-cell BigQuery query editor is a cell type that you can use within your notebook files.\n",
    "\n",
    "Select the BigQuery icon on a given cell to launc the In-cell BigQuery query editor. \n",
    "\n",
    "Reference : \n",
    "\n",
    "https://cloud.google.com/vertex-ai/docs/workbench/instances/bigquery#in-cell\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092b287a-f8a6-4d27-8a09-302026117973",
   "metadata": {},
   "source": [
    "# Method 5 : Use BigQuery DataFrames aka \"BigFrames\" to super charge pandas workloads\n",
    "\n",
    "This is Method 6 of querying data that is stored in BigQuery from within the JupyterLab interface of your Vertex AI Workbench instance.\n",
    "\n",
    "For this method, it is required to use the IPython Jupyter Kernel that comes prepackaged with Vertex AI Workbench Instances. Please select & connect to it now.\n",
    "\n",
    "BigQuery DataFrames provides a Python library **bigframes.pandas** which provides a pandas-compatible API for analytics. \n",
    "\n",
    "Through this library you take advantage of BigQuery data processing by using familiar pandas python APIs. BigQuery DataFrames provides a Pythonic DataFrame powered by the BigQuery engine, and it implements the pandas  APIs by pushing the processing down to BigQuery through SQL conversion. This lets you use BigQuery to explore and process terabytes of data with Python APIs.\n",
    "\n",
    "\n",
    "Reference : \n",
    "\n",
    "https://cloud.google.com/bigquery/docs/bigquery-dataframes-introduction\n",
    "\n",
    "https://cloud.google.com/bigquery/docs/use-bigquery-dataframes\n",
    "\n",
    "https://github.com/googleapis/python-bigquery-dataframes/tree/main/notebooks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68470cab-fe14-4c69-b02c-3f6ba23b6da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://jakevdp.github.io/blog/2017/12/05/installing-python-packages-from-jupyter/\n",
    "# Install a pip package in the current Jupyter kernel\n",
    "# here the package is bigframes https://pypi.org/project/bigframes/\n",
    "import sys\n",
    "!{sys.executable} -m pip install bigframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604b9b28-d1c5-4116-bdb7-fe00892ca759",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bigframes.pandas as bpd\n",
    "\n",
    "# import warnings filter & ignore all future warnings\n",
    "# this is for teaching purposes only, to avoid FutureWarnings to do with bigframe compiler implementation\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Load data from BigQuery\n",
    "print(\"step 1-of-3 :: loading data from BigQuery\")\n",
    "query_or_table = \"bigquery-public-data.ml_datasets.penguins\"\n",
    "bq_df = bpd.read_gbq(query_or_table, use_cache=False)\n",
    "\n",
    "# Compute the mean of this body mass across all species:\n",
    "print(\"step 2-of-3 :: computing mean of body_mass_g column\")\n",
    "average_body_mass = bq_df[\"body_mass_g\"].mean()\n",
    "print(f\"average_body_mass: {average_body_mass}\")\n",
    "\n",
    "# Find the heaviest species using the groupby operation to calculate the\n",
    "# mean body_mass_g:\n",
    "print(\"step 3-of-3 :: computing top speciees by mean body_mass_g\")\n",
    "(\n",
    "    bq_df[\"body_mass_g\"]\n",
    "    .groupby(by=bq_df[\"species\"])\n",
    "    .mean()\n",
    "    .sort_values(ascending=False)\n",
    "    .head(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de67a6a-152e-4d1a-a79e-9d994ae0d62c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Method 6 : Use BigQuery DataFrames aka \"BigFrames\" to super charge scikit learn workloads\n",
    "\n",
    "This is Method 7 of querying data that is stored in BigQuery from within the JupyterLab interface of your Vertex AI Workbench instance.\n",
    "\n",
    "For this method, it is required to use the IPython Jupyter Kernel that comes prepackaged with Vertex AI Workbench Instances. Please select & connect to it now.\n",
    "\n",
    "BigQuery DataFrames provides a library **bigframes.ml** which provides a scikit-learn-like API for machine learning (ML). \n",
    "\n",
    "Through this library you take advantage of BigQuery data processing by using familiar Python scikit-learn-like APIs. BigQuery DataFrames provides a Pythonic DataFrame powered by the BigQuery engine, and it implements the scikit-learn APIs by pushing the processing down to BigQuery through SQL conversion (specifically BigQuery ML). This lets you use BigQuery to explore and process terabytes of data, and also train machine learning (ML) models, all with Python APIs.\n",
    "\n",
    "Reference : \n",
    "\n",
    "https://cloud.google.com/bigquery/docs/bigquery-dataframes-introduction\n",
    "\n",
    "https://cloud.google.com/bigquery/docs/use-bigquery-dataframes\n",
    "\n",
    "https://cloud.google.com/bigquery/docs/bqml-introduction\n",
    "\n",
    "https://github.com/googleapis/python-bigquery-dataframes/tree/main/notebooks\n",
    "\n",
    "https://github.com/googleapis/python-bigquery-dataframes/blob/main/notebooks/getting_started/ml_fundamentals_bq_dataframes.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a9018a-2f9b-48e0-9af6-5dfa68307c56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://jakevdp.github.io/blog/2017/12/05/installing-python-packages-from-jupyter/\n",
    "# Install a pip package in the current Jupyter kernel\n",
    "# here the package is bigframes https://pypi.org/project/bigframes/\n",
    "import sys\n",
    "!{sys.executable} -m pip install bigframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95764d70-918d-46ea-a13b-c7edf06a8c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bigframes.ml.linear_model import LinearRegression\n",
    "import bigframes.pandas as bpd\n",
    "\n",
    "# -------- part 1-of-4 build the training data set & test data set --------\n",
    "print(\"part 1-of-4 build the training data set & test data set\")\n",
    "# Load data from BigQuery\n",
    "query_or_table = \"bigquery-public-data.ml_datasets.penguins\"\n",
    "bq_df = bpd.read_gbq(query_or_table, use_cache=False)\n",
    "\n",
    "# Filter down to the data to the Adelie Penguin species\n",
    "adelie_data = bq_df[bq_df.species == \"Adelie Penguin (Pygoscelis adeliae)\"]\n",
    "\n",
    "# Drop the species column\n",
    "adelie_data = adelie_data.drop(columns=[\"species\"])\n",
    "\n",
    "# Drop rows with nulls to get training data\n",
    "training_data = adelie_data.dropna()\n",
    "\n",
    "# Specify your feature (or input) columns and the label (or output) column:\n",
    "feature_columns = training_data[\n",
    "    [\"island\", \"culmen_length_mm\", \"culmen_depth_mm\", \"flipper_length_mm\", \"sex\"]\n",
    "]\n",
    "label_columns = training_data[[\"body_mass_g\"]]\n",
    "\n",
    "test_data = adelie_data[adelie_data.body_mass_g.isnull()]\n",
    "\n",
    "# -------- part 2-of-4 Fit the model to the data --------\n",
    "print(\"part 2-of-4 Fit the model to the data\")\n",
    "model = LinearRegression()\n",
    "model.fit(feature_columns, label_columns)\n",
    "\n",
    "# -------- part 3-of-4 Evaluate the model fit --------\n",
    "print(\"part 3-of-4 Evaluate the model fit\")\n",
    "# Score the model\n",
    "score = model.score(feature_columns, label_columns)\n",
    "\n",
    "# -------- part 4-of-4 Use the fitted model to make predictions --------\n",
    "print(\"part 4-of-4 Use the fitted model to make predictions\")\n",
    "# Predict using the model\n",
    "result = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22fe1fa-1889-47e6-b9d0-c443d3394fec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -------- Visualize the training set  --------\n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ffbfc1-62ff-4331-921a-d63b4a36150b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -------- inspect the how well the model fit the data   --------\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec3b528-dee3-4977-94f7-971fd9628a28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -------- View the prediction the fitted model made --------\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m124",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m124"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
